# Image captioning
[![PyTorch](https://img.shields.io/badge/Framework-PyTorch-79FFE1)](https://pytorch.org)
![Computer Vision](https://img.shields.io/badge/Type-Computer%20Vision-79FFE1)

A pytorch version of the image captionig model [vit-gpt2-coco-en-ckpts](https://huggingface.co/ydshieh/vit-gpt2-coco-en-ckpts).


## Deploy 
Click a button to deploy a model with [Syndicai](https://syndicai.co).

[![Syndicai-Deploy](https://raw.githubusercontent.com/syndicai/brand/main/button/deploy.svg)](https://app.syndicai.co/newModel?repository=https://github.com/syndicai/models/tree/master/pytorch/image_captioning)


## Example
| input | output |
| --- | --- |
| <img src="sample_data/gibson.png" width="410"> | `a person holding a guitar in their hand` |


## Local run
In order to test the model locally open **demo.ipynb** in the `model` directory.